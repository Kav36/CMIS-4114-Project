{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nvidia-smi -q -d POWER\n",
    "# trainer.train(resume_from_checkpoint=\"./results/checkpoint-500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load SQuAD v2 dataset\n",
    "ds = load_dataset(\"rajpurkar/squad_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available splits\n",
    "print(ds)\n",
    "\n",
    "# Inspect a sample from the training set\n",
    "print(ds['train'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "# Load SQuAD v2 dataset\n",
    "ds = load_dataset(\"rajpurkar/squad_v2\")\n",
    "\n",
    "# Initialize a fast tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Preprocessing function for the dataset\n",
    "def preprocess_data(examples):\n",
    "    # Tokenize context and question with truncation and padding\n",
    "    inputs = tokenizer(\n",
    "        examples['question'],\n",
    "        examples['context'],\n",
    "        truncation=\"only_second\",  # Truncate the context if it's too long\n",
    "        max_length=384,  # Typically used max length for QA\n",
    "        stride=128,\n",
    "        padding=\"max_length\",\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    \n",
    "    # Map answer to the tokenized input\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    \n",
    "    start_positions, end_positions = [], []\n",
    "    \n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # Check if the answer data is available for the current example\n",
    "        if i >= len(answers) or \"answer_start\" not in answers[i] or len(answers[i][\"answer_start\"]) == 0:\n",
    "            # No answer available, set default start and end positions\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # There is an answer, retrieve start and end characters\n",
    "            start_char = answers[i][\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[i][\"text\"][0])\n",
    "            \n",
    "            # Find the start and end of the answer in tokens\n",
    "            token_start_index = 0\n",
    "            token_end_index = 0\n",
    "            for idx, (start, end) in enumerate(offsets):\n",
    "                if start <= start_char < end:\n",
    "                    token_start_index = idx\n",
    "                if start < end_char <= end:\n",
    "                    token_end_index = idx\n",
    "                    break\n",
    "            \n",
    "            start_positions.append(token_start_index)\n",
    "            end_positions.append(token_end_index)\n",
    "    \n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs\n",
    "\n",
    "# Apply to the dataset\n",
    "tokenized_ds = ds.map(preprocess_data, batched=True, remove_columns=ds[\"train\"].column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForQuestionAnswering, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from transformers import BertTokenizerFast\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForQuestionAnswering.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Load and preprocess dataset as before\n",
    "ds = load_dataset(\"rajpurkar/squad_v2\")\n",
    "\n",
    "# Preprocessing function (as defined before)\n",
    "def preprocess_data(examples):\n",
    "    inputs = tokenizer(\n",
    "        examples['question'],\n",
    "        examples['context'],\n",
    "        truncation=\"only_second\",\n",
    "        max_length=384,\n",
    "        stride=128,\n",
    "        padding=\"max_length\",\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    \n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    \n",
    "    start_positions, end_positions = [], []\n",
    "    \n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        if i >= len(answers) or \"answer_start\" not in answers[i] or len(answers[i][\"answer_start\"]) == 0:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            start_char = answers[i][\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[i][\"text\"][0])\n",
    "            token_start_index = 0\n",
    "            token_end_index = 0\n",
    "            for idx, (start, end) in enumerate(offsets):\n",
    "                if start <= start_char < end:\n",
    "                    token_start_index = idx\n",
    "                if start < end_char <= end:\n",
    "                    token_end_index = idx\n",
    "                    break\n",
    "            start_positions.append(token_start_index)\n",
    "            end_positions.append(token_end_index)\n",
    "    \n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs\n",
    "\n",
    "# Apply preprocessing\n",
    "tokenized_ds = ds.map(preprocess_data, batched=True, remove_columns=ds[\"train\"].column_names)\n",
    "\n",
    "# Define data collator for dynamic padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Set training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "# trainer.train(resume_from_checkpoint=\"./results/checkpoint-33500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating all checkpoints to find the best one...\n",
      "Evaluating checkpoint: ./results\\checkpoint-500\n",
      "Checkpoint: ./results\\checkpoint-500, Answer: Paris, Score: 0.15826915204524994\n",
      "Evaluating checkpoint: ./results\\checkpoint-1000\n",
      "Checkpoint: ./results\\checkpoint-1000, Answer: Paris, Score: 0.2653363049030304\n",
      "Evaluating checkpoint: ./results\\checkpoint-1500\n",
      "Checkpoint: ./results\\checkpoint-1500, Answer: Paris, Score: 0.3415960669517517\n",
      "Evaluating checkpoint: ./results\\checkpoint-2000\n",
      "Checkpoint: ./results\\checkpoint-2000, Answer: Paris, Score: 0.22488351166248322\n",
      "Evaluating checkpoint: ./results\\checkpoint-2500\n",
      "Checkpoint: ./results\\checkpoint-2500, Answer: Paris, Score: 0.4180004596710205\n",
      "Evaluating checkpoint: ./results\\checkpoint-3000\n",
      "Checkpoint: ./results\\checkpoint-3000, Answer: Paris, Score: 0.538913369178772\n",
      "Evaluating checkpoint: ./results\\checkpoint-3500\n",
      "Checkpoint: ./results\\checkpoint-3500, Answer: Paris, Score: 0.3645639419555664\n",
      "Evaluating checkpoint: ./results\\checkpoint-4000\n",
      "Checkpoint: ./results\\checkpoint-4000, Answer: Paris, Score: 0.5036070346832275\n",
      "Evaluating checkpoint: ./results\\checkpoint-4500\n",
      "Checkpoint: ./results\\checkpoint-4500, Answer: Paris, Score: 0.5486152768135071\n",
      "Evaluating checkpoint: ./results\\checkpoint-5000\n",
      "Checkpoint: ./results\\checkpoint-5000, Answer: Paris, Score: 0.43748655915260315\n",
      "Evaluating checkpoint: ./results\\checkpoint-5500\n",
      "Checkpoint: ./results\\checkpoint-5500, Answer: Paris, Score: 0.7311595678329468\n",
      "Evaluating checkpoint: ./results\\checkpoint-6000\n",
      "Checkpoint: ./results\\checkpoint-6000, Answer: Paris, Score: 0.6113681793212891\n",
      "Evaluating checkpoint: ./results\\checkpoint-6500\n",
      "Checkpoint: ./results\\checkpoint-6500, Answer: Paris, Score: 0.5981680750846863\n",
      "Evaluating checkpoint: ./results\\checkpoint-7000\n",
      "Checkpoint: ./results\\checkpoint-7000, Answer: Paris, Score: 0.09447342157363892\n",
      "Evaluating checkpoint: ./results\\checkpoint-7500\n",
      "Checkpoint: ./results\\checkpoint-7500, Answer: Paris, Score: 0.39137211441993713\n",
      "Evaluating checkpoint: ./results\\checkpoint-8000\n",
      "Checkpoint: ./results\\checkpoint-8000, Answer: Paris, Score: 0.5245614051818848\n",
      "Evaluating checkpoint: ./results\\checkpoint-8500\n",
      "Checkpoint: ./results\\checkpoint-8500, Answer: Paris, Score: 0.20557594299316406\n",
      "Evaluating checkpoint: ./results\\checkpoint-9000\n",
      "Checkpoint: ./results\\checkpoint-9000, Answer: Paris, Score: 0.031776655465364456\n",
      "Evaluating checkpoint: ./results\\checkpoint-9500\n",
      "Checkpoint: ./results\\checkpoint-9500, Answer: Paris, Score: 0.2891694903373718\n",
      "Evaluating checkpoint: ./results\\checkpoint-10000\n",
      "Checkpoint: ./results\\checkpoint-10000, Answer: Paris, Score: 0.14202575385570526\n",
      "Evaluating checkpoint: ./results\\checkpoint-10500\n",
      "Checkpoint: ./results\\checkpoint-10500, Answer: Paris, Score: 0.3823273181915283\n",
      "Evaluating checkpoint: ./results\\checkpoint-11000\n",
      "Checkpoint: ./results\\checkpoint-11000, Answer: Paris, Score: 0.06781518459320068\n",
      "Evaluating checkpoint: ./results\\checkpoint-11500\n",
      "Checkpoint: ./results\\checkpoint-11500, Answer: Paris, Score: 0.10721343010663986\n",
      "Evaluating checkpoint: ./results\\checkpoint-12000\n",
      "Checkpoint: ./results\\checkpoint-12000, Answer: Paris, Score: 0.46749308705329895\n",
      "Evaluating checkpoint: ./results\\checkpoint-12500\n",
      "Checkpoint: ./results\\checkpoint-12500, Answer: Paris, Score: 0.20621375739574432\n",
      "Evaluating checkpoint: ./results\\checkpoint-13000\n",
      "Checkpoint: ./results\\checkpoint-13000, Answer: Paris, Score: 0.3109326958656311\n",
      "Evaluating checkpoint: ./results\\checkpoint-13500\n",
      "Checkpoint: ./results\\checkpoint-13500, Answer: Paris, Score: 0.3633050322532654\n",
      "Evaluating checkpoint: ./results\\checkpoint-14000\n",
      "Checkpoint: ./results\\checkpoint-14000, Answer: Paris, Score: 0.7351104617118835\n",
      "Evaluating checkpoint: ./results\\checkpoint-14500\n",
      "Checkpoint: ./results\\checkpoint-14500, Answer: Paris, Score: 0.10884930193424225\n",
      "Evaluating checkpoint: ./results\\checkpoint-15000\n",
      "Checkpoint: ./results\\checkpoint-15000, Answer: Paris, Score: 0.4880541265010834\n",
      "Evaluating checkpoint: ./results\\checkpoint-15500\n",
      "Checkpoint: ./results\\checkpoint-15500, Answer: Paris, Score: 0.5434423685073853\n",
      "Evaluating checkpoint: ./results\\checkpoint-16000\n",
      "Checkpoint: ./results\\checkpoint-16000, Answer: Paris, Score: 0.3431720733642578\n",
      "Evaluating checkpoint: ./results\\checkpoint-16500\n",
      "Checkpoint: ./results\\checkpoint-16500, Answer: Paris, Score: 0.2741735875606537\n",
      "Evaluating checkpoint: ./results\\checkpoint-17000\n",
      "Checkpoint: ./results\\checkpoint-17000, Answer: Paris, Score: 0.21687713265419006\n",
      "Evaluating checkpoint: ./results\\checkpoint-17500\n",
      "Checkpoint: ./results\\checkpoint-17500, Answer: Paris, Score: 0.2041422426700592\n",
      "Evaluating checkpoint: ./results\\checkpoint-18000\n",
      "Checkpoint: ./results\\checkpoint-18000, Answer: Paris, Score: 0.1447194218635559\n",
      "Evaluating checkpoint: ./results\\checkpoint-18500\n",
      "Checkpoint: ./results\\checkpoint-18500, Answer: Paris, Score: 0.1732553243637085\n",
      "Evaluating checkpoint: ./results\\checkpoint-19000\n",
      "Checkpoint: ./results\\checkpoint-19000, Answer: Paris, Score: 0.28449976444244385\n",
      "Evaluating checkpoint: ./results\\checkpoint-19500\n",
      "Checkpoint: ./results\\checkpoint-19500, Answer: Paris, Score: 0.06483624130487442\n",
      "Evaluating checkpoint: ./results\\checkpoint-20000\n",
      "Checkpoint: ./results\\checkpoint-20000, Answer: Paris, Score: 0.24504148960113525\n",
      "Evaluating checkpoint: ./results\\checkpoint-20500\n",
      "Checkpoint: ./results\\checkpoint-20500, Answer: Paris, Score: 0.15341432392597198\n",
      "Evaluating checkpoint: ./results\\checkpoint-21000\n",
      "Checkpoint: ./results\\checkpoint-21000, Answer: Paris, Score: 0.5159323215484619\n",
      "Evaluating checkpoint: ./results\\checkpoint-21500\n",
      "Checkpoint: ./results\\checkpoint-21500, Answer: Paris, Score: 0.07298348098993301\n",
      "Evaluating checkpoint: ./results\\checkpoint-22000\n",
      "Checkpoint: ./results\\checkpoint-22000, Answer: Paris, Score: 0.2670150399208069\n",
      "Evaluating checkpoint: ./results\\checkpoint-22500\n",
      "Checkpoint: ./results\\checkpoint-22500, Answer: Paris, Score: 0.23452191054821014\n",
      "Evaluating checkpoint: ./results\\checkpoint-23000\n",
      "Checkpoint: ./results\\checkpoint-23000, Answer: Paris, Score: 0.3013380467891693\n",
      "Evaluating checkpoint: ./results\\checkpoint-23500\n",
      "Checkpoint: ./results\\checkpoint-23500, Answer: Paris, Score: 0.11258337646722794\n",
      "Evaluating checkpoint: ./results\\checkpoint-24000\n",
      "Checkpoint: ./results\\checkpoint-24000, Answer: Paris, Score: 0.07954972237348557\n",
      "Evaluating checkpoint: ./results\\checkpoint-24500\n",
      "Checkpoint: ./results\\checkpoint-24500, Answer: Paris, Score: 0.3085378408432007\n",
      "Evaluating checkpoint: ./results\\checkpoint-25000\n",
      "Checkpoint: ./results\\checkpoint-25000, Answer: Paris, Score: 0.2123662680387497\n",
      "Evaluating checkpoint: ./results\\checkpoint-25500\n",
      "Checkpoint: ./results\\checkpoint-25500, Answer: Paris, Score: 0.12034258991479874\n",
      "Evaluating checkpoint: ./results\\checkpoint-26000\n",
      "Checkpoint: ./results\\checkpoint-26000, Answer: Paris, Score: 0.20229026675224304\n",
      "Evaluating checkpoint: ./results\\checkpoint-26500\n",
      "Checkpoint: ./results\\checkpoint-26500, Answer: Paris, Score: 0.11756516247987747\n",
      "Evaluating checkpoint: ./results\\checkpoint-27000\n",
      "Checkpoint: ./results\\checkpoint-27000, Answer: Paris, Score: 0.046733587980270386\n",
      "Evaluating checkpoint: ./results\\checkpoint-27500\n",
      "Checkpoint: ./results\\checkpoint-27500, Answer: Paris, Score: 0.08311755210161209\n",
      "Evaluating checkpoint: ./results\\checkpoint-28000\n",
      "Checkpoint: ./results\\checkpoint-28000, Answer: Paris, Score: 0.05820731446146965\n",
      "Evaluating checkpoint: ./results\\checkpoint-28500\n",
      "Checkpoint: ./results\\checkpoint-28500, Answer: Paris, Score: 0.03061041235923767\n",
      "Evaluating checkpoint: ./results\\checkpoint-29000\n",
      "Checkpoint: ./results\\checkpoint-29000, Answer: Paris, Score: 0.12459038197994232\n",
      "Evaluating checkpoint: ./results\\checkpoint-29500\n",
      "Checkpoint: ./results\\checkpoint-29500, Answer: Paris, Score: 0.035732947289943695\n",
      "Evaluating checkpoint: ./results\\checkpoint-30000\n",
      "Checkpoint: ./results\\checkpoint-30000, Answer: Paris, Score: 0.292466938495636\n",
      "Evaluating checkpoint: ./results\\checkpoint-30500\n",
      "Checkpoint: ./results\\checkpoint-30500, Answer: Paris, Score: 0.017531055957078934\n",
      "Evaluating checkpoint: ./results\\checkpoint-31000\n",
      "Checkpoint: ./results\\checkpoint-31000, Answer: Paris, Score: 0.16067585349082947\n",
      "Evaluating checkpoint: ./results\\checkpoint-31500\n",
      "Checkpoint: ./results\\checkpoint-31500, Answer: Paris, Score: 0.016673864796757698\n",
      "Evaluating checkpoint: ./results\\checkpoint-32000\n",
      "Checkpoint: ./results\\checkpoint-32000, Answer: Paris, Score: 0.061148904263973236\n",
      "Evaluating checkpoint: ./results\\checkpoint-32500\n",
      "Checkpoint: ./results\\checkpoint-32500, Answer: Paris, Score: 0.0702587366104126\n",
      "Evaluating checkpoint: ./results\\checkpoint-33000\n",
      "Checkpoint: ./results\\checkpoint-33000, Answer: Paris, Score: 0.30266231298446655\n",
      "Evaluating checkpoint: ./results\\checkpoint-33500\n",
      "Checkpoint: ./results\\checkpoint-33500, Answer: Paris, Score: 0.1756170243024826\n",
      "Evaluating checkpoint: ./results\\checkpoint-34000\n",
      "Checkpoint: ./results\\checkpoint-34000, Answer: Paris, Score: 0.3467467725276947\n",
      "Evaluating checkpoint: ./results\\checkpoint-34500\n",
      "Checkpoint: ./results\\checkpoint-34500, Answer: Paris, Score: 0.09202890843153\n",
      "Evaluating checkpoint: ./results\\checkpoint-35000\n",
      "Checkpoint: ./results\\checkpoint-35000, Answer: Paris, Score: 0.027441492304205894\n",
      "Evaluating checkpoint: ./results\\checkpoint-35500\n",
      "Checkpoint: ./results\\checkpoint-35500, Answer: Paris, Score: 0.026517143473029137\n",
      "Evaluating checkpoint: ./results\\checkpoint-36000\n",
      "Checkpoint: ./results\\checkpoint-36000, Answer: Paris, Score: 0.13844861090183258\n",
      "Evaluating checkpoint: ./results\\checkpoint-36500\n",
      "Checkpoint: ./results\\checkpoint-36500, Answer: Paris, Score: 0.6021637916564941\n",
      "Evaluating checkpoint: ./results\\checkpoint-37000\n",
      "Checkpoint: ./results\\checkpoint-37000, Answer: Paris, Score: 0.1629137396812439\n",
      "Evaluating checkpoint: ./results\\checkpoint-37500\n",
      "Checkpoint: ./results\\checkpoint-37500, Answer: Paris, Score: 0.053171306848526\n",
      "Evaluating checkpoint: ./results\\checkpoint-38000\n",
      "Checkpoint: ./results\\checkpoint-38000, Answer: Paris, Score: 0.17698225378990173\n",
      "Evaluating checkpoint: ./results\\checkpoint-38500\n",
      "Checkpoint: ./results\\checkpoint-38500, Answer: Paris, Score: 0.12945152819156647\n",
      "Evaluating checkpoint: ./results\\checkpoint-39000\n",
      "Checkpoint: ./results\\checkpoint-39000, Answer: Paris, Score: 0.05738099664449692\n",
      "Evaluating checkpoint: ./results\\checkpoint-39500\n",
      "Checkpoint: ./results\\checkpoint-39500, Answer: Paris, Score: 0.13708175718784332\n",
      "Evaluating checkpoint: ./results\\checkpoint-40000\n",
      "Checkpoint: ./results\\checkpoint-40000, Answer: Paris, Score: 0.1653296798467636\n",
      "Evaluating checkpoint: ./results\\checkpoint-40500\n",
      "Checkpoint: ./results\\checkpoint-40500, Answer: Paris, Score: 0.20714597404003143\n",
      "Evaluating checkpoint: ./results\\checkpoint-41000\n",
      "Checkpoint: ./results\\checkpoint-41000, Answer: Paris, Score: 0.12565623223781586\n",
      "Evaluating checkpoint: ./results\\checkpoint-41500\n",
      "Checkpoint: ./results\\checkpoint-41500, Answer: Paris, Score: 0.08772513270378113\n",
      "Evaluating checkpoint: ./results\\checkpoint-42000\n",
      "Checkpoint: ./results\\checkpoint-42000, Answer: Paris, Score: 0.060075290501117706\n",
      "Evaluating checkpoint: ./results\\checkpoint-42500\n",
      "Checkpoint: ./results\\checkpoint-42500, Answer: Paris, Score: 0.29198652505874634\n",
      "Evaluating checkpoint: ./results\\checkpoint-43000\n",
      "Checkpoint: ./results\\checkpoint-43000, Answer: Paris, Score: 0.10083001106977463\n",
      "Evaluating checkpoint: ./results\\checkpoint-43500\n",
      "Checkpoint: ./results\\checkpoint-43500, Answer: Paris, Score: 0.04736409708857536\n",
      "Evaluating checkpoint: ./results\\checkpoint-44000\n",
      "Checkpoint: ./results\\checkpoint-44000, Answer: Paris, Score: 0.05758622661232948\n",
      "Evaluating checkpoint: ./results\\checkpoint-44500\n",
      "Checkpoint: ./results\\checkpoint-44500, Answer: Paris, Score: 0.031570274382829666\n",
      "Evaluating checkpoint: ./results\\checkpoint-45000\n",
      "Checkpoint: ./results\\checkpoint-45000, Answer: Paris, Score: 0.0944579616189003\n",
      "Evaluating checkpoint: ./results\\checkpoint-45500\n",
      "Checkpoint: ./results\\checkpoint-45500, Answer: Paris, Score: 0.1921440213918686\n",
      "Evaluating checkpoint: ./results\\checkpoint-46000\n",
      "Checkpoint: ./results\\checkpoint-46000, Answer: Paris, Score: 0.24349795281887054\n",
      "Evaluating checkpoint: ./results\\checkpoint-46500\n",
      "Checkpoint: ./results\\checkpoint-46500, Answer: Paris, Score: 0.27126023173332214\n",
      "Evaluating checkpoint: ./results\\checkpoint-47000\n",
      "Checkpoint: ./results\\checkpoint-47000, Answer: Paris, Score: 0.1421826034784317\n",
      "Evaluating checkpoint: ./results\\checkpoint-47500\n",
      "Checkpoint: ./results\\checkpoint-47500, Answer: Paris, Score: 0.1323266476392746\n",
      "Evaluating checkpoint: ./results\\checkpoint-48000\n",
      "Checkpoint: ./results\\checkpoint-48000, Answer: Paris, Score: 0.12523303925991058\n",
      "Evaluating checkpoint: ./results\\checkpoint-48500\n",
      "Checkpoint: ./results\\checkpoint-48500, Answer: Paris, Score: 0.16139550507068634\n",
      "Evaluating checkpoint: ./results\\checkpoint-49000\n",
      "Checkpoint: ./results\\checkpoint-49000, Answer: Paris, Score: 0.13890892267227173\n",
      "Evaluating checkpoint: ./results\\checkpoint-49410\n",
      "Checkpoint: ./results\\checkpoint-49410, Answer: Paris, Score: 0.13935722410678864\n",
      "Best checkpoint: ./results\\checkpoint-14000 with score 0.7351104617118835\n",
      "Saving the best checkpoint to: ./final_model\n",
      "Reloading the saved model for verification...\n",
      "Final Answer: Paris, Score: 0.13935722410678864\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForQuestionAnswering, BertTokenizerFast, pipeline\n",
    "import os\n",
    "\n",
    "# Path to the directory containing checkpoints\n",
    "checkpoints_dir = \"./results\"\n",
    "\n",
    "# List all checkpoints and sort them by training step number\n",
    "checkpoints = [os.path.join(checkpoints_dir, d) for d in os.listdir(checkpoints_dir) if d.startswith(\"checkpoint\")]\n",
    "checkpoints.sort(key=lambda x: int(x.split('-')[-1]))\n",
    "\n",
    "# Example validation data\n",
    "question = \"What is the capital of France?\"\n",
    "context = \"France is a country in Europe. The capital of France is Paris.\"\n",
    "\n",
    "best_checkpoint = None\n",
    "best_score = float(\"-inf\")\n",
    "\n",
    "# Ensure device selection\n",
    "device = 0  # GPU 0\n",
    "\n",
    "print(\"Evaluating all checkpoints to find the best one...\")\n",
    "for checkpoint in checkpoints:\n",
    "    print(f\"Evaluating checkpoint: {checkpoint}\")\n",
    "    # Load model for this checkpoint\n",
    "    model = BertForQuestionAnswering.from_pretrained(checkpoint)\n",
    "    # Load tokenizer from original base model\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    # Create a pipeline for question answering with GPU\n",
    "    qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device=device)\n",
    "\n",
    "    # Perform QA inference and evaluate the result\n",
    "    result = qa_pipeline(question=question, context=context)\n",
    "    print(f\"Checkpoint: {checkpoint}, Answer: {result['answer']}, Score: {result['score']}\")\n",
    "\n",
    "    # Track the best checkpoint based on the score\n",
    "    if result['score'] > best_score:\n",
    "        best_score = result['score']\n",
    "        best_checkpoint = checkpoint\n",
    "\n",
    "# Output the best checkpoint\n",
    "print(f\"Best checkpoint: {best_checkpoint} with score {best_score}\")\n",
    "\n",
    "# Save the best checkpoint to a permanent location\n",
    "final_model_path = \"./final_model\"\n",
    "print(f\"Saving the best checkpoint to: {final_model_path}\")\n",
    "tokenizer.save_pretrained(final_model_path)\n",
    "model.save_pretrained(final_model_path)\n",
    "\n",
    "# Reload the saved model for verification\n",
    "print(\"Reloading the saved model for verification...\")\n",
    "tokenizer = BertTokenizerFast.from_pretrained(final_model_path)\n",
    "model = BertForQuestionAnswering.from_pretrained(final_model_path)\n",
    "\n",
    "# Use the saved model for inference\n",
    "qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device=device)\n",
    "result = qa_pipeline(question=question, context=context)\n",
    "print(f\"Final Answer: {result['answer']}, Score: {result['score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: check to test for possible deadlock conditions, Score: 0.17190447449684143\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForQuestionAnswering, BertTokenizerFast, pipeline\n",
    "\n",
    "# Load the fine-tuned model\n",
    "model_path = \"./final_model\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_path)\n",
    "model = BertForQuestionAnswering.from_pretrained(model_path)\n",
    "\n",
    "# Create a pipeline for question answering\n",
    "qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device=0)  # Ensure GPU usage (device=0)\n",
    "\n",
    "# Example usage\n",
    "question = \"what is safe state\"\n",
    "context = \"The Banker's algorithm is a resource allocation and deadlock avoidance algorithm. This was developed by Edsger Dijkstra. This tests for safety by simulating the allocation of predetermined maximum possible amounts of all resources, and then makes a safe-state check to test for possible deadlock conditions for all other pending activities, before deciding whether allocation should be allowed to continue.\"\n",
    "\n",
    "result = qa_pipeline(question=question, context=context)\n",
    "print(f\"Answer: {result['answer']}, Score: {result['score']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
